{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f912da7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /Users/nikolaus/opt/anaconda3/lib/python3.9/site-packages (1.21.5)\r\n",
      "Requirement already satisfied: pandas in /Users/nikolaus/opt/anaconda3/lib/python3.9/site-packages (1.4.4)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/nikolaus/opt/anaconda3/lib/python3.9/site-packages (from pandas) (2.8.2)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/nikolaus/opt/anaconda3/lib/python3.9/site-packages (from pandas) (2022.1)\r\n",
      "Requirement already satisfied: numpy>=1.18.5 in /Users/nikolaus/opt/anaconda3/lib/python3.9/site-packages (from pandas) (1.21.5)\r\n",
      "Requirement already satisfied: six>=1.5 in /Users/nikolaus/opt/anaconda3/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\r\n",
      "Requirement already satisfied: scipy in /Users/nikolaus/opt/anaconda3/lib/python3.9/site-packages (1.9.1)\r\n",
      "Requirement already satisfied: numpy<1.25.0,>=1.18.5 in /Users/nikolaus/opt/anaconda3/lib/python3.9/site-packages (from scipy) (1.21.5)\r\n"
     ]
    }
   ],
   "source": [
    "# installations\n",
    "!pip install numpy\n",
    "!pip install pandas\n",
    "!pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Running a test\n",
    "The following chunk runs a lightweight version of the experiment once, with only a handful of users.\n",
    "At each round, the model gets fitted to every user in the dataset and a regret score is calculated.\n",
    "At the end of all rounds (by default 100 rounds) the minimum cumulative regret indicates, which model performs best.\n",
    "According to the source paper, *ts-seg-pessimistic* performs best on the offline experiment. Hence, they tested this models performance in a cascade versus non-cascade offline experiment, in which case the *ts-seg-pessimistic cascade* model performed best. This model also caused the highest display-to-stream gain.\n",
    "All featured tests' results showed statistical significance at the 1% level. However, the paper does not state how those statistical tests were conducted.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:__main__:LOADING DATA\r\n",
      "INFO:__main__:Loading playlist data\r\n",
      "INFO:__main__:Loading user data\r\n",
      " \r\n",
      "\r\n",
      "9\r\n",
      "9\r\n",
      "1.0\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/Users/nikolaus/Documents/Uni/TU/DS Experiment Design/exercise 2/carousel_reproduction/main.py\", line 79, in <module>\r\n",
      "    raise hell\r\n",
      "NameError: name 'hell' is not defined\r\n",
      "Figure(640x480)\r\n"
     ]
    }
   ],
   "source": [
    "# small dataset, all policies\n",
    "!python main.py --users_path data/user_features_small.csv --policies random,etc-seg-explore,etc-seg-exploit,epsilon-greedy-explore,epsilon-greedy-exploit,kl-ucb-seg,ts-seg-naive,ts-seg-pessimistic,ts-lin-naive,ts-lin-pessimistic --n_users_per_round 9 --output_path general_experiment_results.json\n",
    "!python plot_results.py --data_path general_experiment_results.json\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:__main__:LOADING DATA\r\n",
      "INFO:__main__:Loading playlist data\r\n",
      "INFO:__main__:Loading user data\r\n",
      " \r\n",
      "\r\n",
      "974960\r\n",
      "20000\r\n",
      "0.020513662098957906\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/Users/nikolaus/Documents/Uni/TU/DS Experiment Design/exercise 2/carousel_reproduction/main.py\", line 79, in <module>\r\n",
      "    raise hell\r\n",
      "NameError: name 'hell' is not defined\r\n",
      "Figure(640x480)\r\n"
     ]
    }
   ],
   "source": [
    "# full dataset, two policies\n",
    "!python main.py --policies random,ts-seg-pessimistic --print_every 5 --output_path general_experiment_results.json\n",
    "!python plot_results.py --data_path general_experiment_results.json"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# My suggestion for reproducing tests\n",
    "We can reproduce the full offline experiment. We just need to find a way to compare results.\n",
    "https://machinelearningmastery.com/statistical-significance-tests-for-comparing-machine-learning-algorithms/\n",
    "According to this paper, it is common to do a 10-fold cross validation on the dataset at hand and grab the mean/median success metric of each model as a statistic for that model. We would then have the following hypotheses:\n",
    " * h0: there is no difference in model performances, i.e. ts-seg-pessimistic (cascade) performs just as well as the other models, i.e. the lower cumulative regret of the tests are due to chance\n",
    "  * h1: there is a difference in model performances, i.e. ts-seg-pessimistic (cascade) outperforms the other models\n",
    "\n",
    "### Does the original code cross-validate?\n",
    "No, but something different. The argument *n_users_per_round* (default 20.000, 1% of full dataset) states, how many users actually get recommended anything in any round. That means that the actual dataset never changes for every time you run the experiment, but the sample on which you fit and evaluate the model changes on every round.\n",
    "According to Brownlee (2018, https://machinelearningmastery.com/statistical-significance-tests-for-comparing-machine-learning-algorithms/), this testing behaviour violates a key assumption of the Student's t-test, which is independency of observations in each sample per round.\n",
    "My suggestion for fixing this. Run the full experiment k (10) times and give the program either 10% of the data to work on, while either continuing to let it use a sample of 20.000 users or even telling it not to resample anything, but rather work on the whole data. Instead of rewriting the source code to include cross-validation, I will split the users dataset itself into k samples and run the whole main.py file k times, with different arguments each time, i.e. changing the results-output-filename.\n",
    "The only rewriting I will do, is putting the main workflow of the main.py file into a separate main() function with arguments passed in python rather than from the command line, so I can execute it using this notebook.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "run_experiment() got an unexpected keyword argument 'user_indices'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/wn/h7d3tkjj12g2j3lhccrbhnlc0000gn/T/ipykernel_7463/3996365567.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mexperiment\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mrun_experiment\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 4\u001B[0;31m run_experiment(\n\u001B[0m\u001B[1;32m      5\u001B[0m         \u001B[0musers_path\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m\"data/user_features.csv\"\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      6\u001B[0m         \u001B[0mplaylists_path\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m\"data/playlist_features.csv\"\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mTypeError\u001B[0m: run_experiment() got an unexpected keyword argument 'user_indices'"
     ]
    }
   ],
   "source": [
    "# test run of the new experiment.py\n",
    "\n",
    "from experiment import run_experiment\n",
    "run_experiment(\n",
    "        users_path=\"data/user_features.csv\",\n",
    "        playlists_path=\"data/playlist_features.csv\",\n",
    "        output_path=\"results.json\",\n",
    "        policies=\"random,ts-seg-naive\",\n",
    "        n_recos=12,\n",
    "        l_init=3,\n",
    "        n_users_per_round=20000,\n",
    "        n_rounds=100,\n",
    "        print_every=10,\n",
    "        user_indices=[3, 6, 7, 9, 12, 36, 47]\n",
    "\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting 97497 rows from user_features_s.csv into 10 files with 9749 rows each ...\n",
      "\t saving file number 0: [85946  3872 31780 ... 47937 55567 82517]\n",
      "\t saving file number 1: [22586 31592 96232 ... 73702 64310 54891]\n",
      "\t saving file number 2: [76709 75098  2673 ...  5544 56415 92977]\n",
      "\t saving file number 3: [63423 41334 63777 ... 60094 15604 37713]\n",
      "\t saving file number 4: [19728 31058 70798 ... 16191 62876 61679]\n",
      "\t saving file number 5: [88045 25461  6879 ... 32632 20313 31835]\n",
      "\t saving file number 6: [94082 32249 73644 ... 48007 74561  1241]\n",
      "\t saving file number 7: [69563 19952 90072 ... 81243 24419 55885]\n",
      "\t saving file number 8: [10380  9242 92649 ... 37100 44500 91414]\n",
      "\t saving file number 9: [50418 58201 96554 ... 38744 74385 92454]\n",
      "All done. 7 users remain unsaved: [ 4459  8820 14441 42417 69647 69973 93180]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def split_dataset(data_filename, k):\n",
    "        # grabs a datafile from the folder \"data/\"\n",
    "        # randomly splits the dataset into k smaller sets of equal size\n",
    "        # saves them in the folder \"data/split/\"\n",
    "\n",
    "        with open(f\"data/{data_filename}\", \"r\") as f:\n",
    "                full = np.array(f.readlines())\n",
    "\n",
    "        data_filename, suffix = data_filename.split(\".\")\n",
    "\n",
    "        # header row should be separate\n",
    "        header_row, full = full[0], full[0:]\n",
    "\n",
    "        N = len(full) # number of all rows\n",
    "        indices = np.array(list((range(N)))) # numbers from 0 to N\n",
    "        n = N // k # number of rows per k\n",
    "\n",
    "        print(f\"Splitting {N} rows from {data_filename}.{suffix} into {k} files with {n} rows each ...\")\n",
    "\n",
    "        for i in range(k):\n",
    "                # get random row numbers from 0 to the length of indices (starts at N)\n",
    "                random_indices = np.random.choice(len(indices), n, replace=False)\n",
    "                # grab random row numbers of the remaining ones\n",
    "                sample_indices = indices[random_indices]\n",
    "                # remove the selected row numbers from the indices list\n",
    "                indices = np.delete(indices, random_indices)\n",
    "                # create a sample\n",
    "                sample = full[sample_indices]\n",
    "                # add the header row\n",
    "                sample = np.append(header_row, sample)\n",
    "                # save the sample\n",
    "                print(f\"\\t saving file number {i}: {sample_indices}\")\n",
    "                f = f\"data/split/{data_filename}_{i}.{suffix}\"\n",
    "                with open(f, \"w\") as f:\n",
    "                        f.writelines(list(sample))\n",
    "\n",
    "\n",
    "        print(f\"All done. {len(indices)} users remain unsaved: {indices}\")\n",
    "        print()\n",
    "        del full\n",
    "        del indices\n",
    "        del sample\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Preparing k datasets\n",
    "data_filename = \"user_features.csv\"\n",
    "data_filename = \"user_features_s.csv\"\n",
    "\n",
    "k = 10\n",
    "\n",
    "split_dataset(data_filename, k)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Data for testing\n",
    "* data/split/: small data\n",
    "* data/splitL: big data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:experiment:LOADING DATA\n",
      "INFO:experiment:Loading playlist data\n",
      "INFO:experiment:Loading user data\n",
      " \n",
      "\n",
      "INFO:experiment:SETTING UP SIMULATION ENVIRONMENT\n",
      "INFO:experiment:for 9749 users, 862 playlists, 12 recommendations per carousel \n",
      " \n",
      "\n",
      "INFO:experiment:SETTING UP POLICIES\n",
      "INFO:experiment:Policies to evaluate: random,etc-seg-explore,etc-seg-exploit,epsilon-greedy-explore,epsilon-greedy-exploit,kl-ucb-seg,ts-seg-naive,ts-seg-pessimistic,ts-lin-naive,ts-lin-pessimistic \n",
      " \n",
      "\n",
      "INFO:experiment:STARTING SIMULATIONS\n",
      "INFO:experiment:for 100 rounds, with 9749 users per round (randomly drawn with replacement)\n",
      " \n",
      "\n",
      "INFO:experiment:Round: 1/100. Elapsed time: 230.721847 sec.\n",
      "INFO:experiment:Cumulative regrets: \n",
      "\trandom : 6394.4675012742355\n",
      "\tetc-seg-explore : 6397.4675012742355\n",
      "\tetc-seg-exploit : 6418.4675012742355\n",
      "\tepsilon-greedy-explore : 6456.4675012742355\n",
      "\tepsilon-greedy-exploit : 6379.4675012742355\n",
      "\tkl-ucb-seg : 6384.4675012742355\n",
      "\tts-seg-naive : 6366.4675012742355\n",
      "\tts-seg-pessimistic : 6334.4675012742355\n",
      "\tts-lin-naive : 6374.4675012742355\n",
      "\tts-lin-pessimistic : 6435.4675012742355 \n",
      "\n",
      "INFO:experiment:Round: 25/100. Elapsed time: 4583.533886 sec.\n",
      "INFO:experiment:Cumulative regrets: \n",
      "\trandom : 159798.86615723727\n",
      "\tetc-seg-explore : 151655.86615723727\n",
      "\tetc-seg-exploit : 147801.86615723727\n",
      "\tepsilon-greedy-explore : 59216.86615723725\n",
      "\tepsilon-greedy-exploit : 58558.86615723725\n",
      "\tkl-ucb-seg : 148009.86615723727\n",
      "\tts-seg-naive : 79812.86615723725\n",
      "\tts-seg-pessimistic : 53394.86615723725\n",
      "\tts-lin-naive : 111355.86615723725\n",
      "\tts-lin-pessimistic : 111993.86615723725 \n",
      "\n",
      "INFO:experiment:Round: 50/100. Elapsed time: 8351.846949 sec.\n",
      "INFO:experiment:Cumulative regrets: \n",
      "\trandom : 319811.0475372305\n",
      "\tetc-seg-explore : 312694.0475372305\n",
      "\tetc-seg-exploit : 187577.04753723054\n",
      "\tepsilon-greedy-explore : 95253.04753723052\n",
      "\tepsilon-greedy-exploit : 101199.04753723052\n",
      "\tkl-ucb-seg : 249950.04753723054\n",
      "\tts-seg-naive : 122246.04753723054\n",
      "\tts-seg-pessimistic : 77191.04753723054\n",
      "\tts-lin-naive : 143392.04753723054\n",
      "\tts-lin-pessimistic : 142007.0475372305 \n",
      "\n",
      "INFO:experiment:Round: 75/100. Elapsed time: 12066.445546 sec.\n",
      "INFO:experiment:Cumulative regrets: \n",
      "\trandom : 479978.94138536084\n",
      "\tetc-seg-explore : 468734.94138536084\n",
      "\tetc-seg-exploit : 195045.94138536087\n",
      "\tepsilon-greedy-explore : 125433.9413853609\n",
      "\tepsilon-greedy-exploit : 138831.9413853609\n",
      "\tkl-ucb-seg : 314726.94138536084\n",
      "\tts-seg-naive : 154635.9413853609\n",
      "\tts-seg-pessimistic : 95541.9413853609\n",
      "\tts-lin-naive : 161549.9413853609\n",
      "\tts-lin-pessimistic : 159484.9413853609 \n",
      "\n",
      "INFO:experiment:Round: 100/100. Elapsed time: 15769.305309 sec.\n",
      "INFO:experiment:Cumulative regrets: \n",
      "\trandom : 639748.1805593389\n",
      "\tetc-seg-explore : 606201.1805593389\n",
      "\tetc-seg-exploit : 201553.1805593389\n",
      "\tepsilon-greedy-explore : 152835.1805593389\n",
      "\tepsilon-greedy-exploit : 173679.1805593389\n",
      "\tkl-ucb-seg : 358169.1805593389\n",
      "\tts-seg-naive : 181350.1805593389\n",
      "\tts-seg-pessimistic : 110466.18055933893\n",
      "\tts-lin-naive : 174629.1805593389\n",
      "\tts-lin-pessimistic : 171064.1805593389 \n",
      "\n",
      "INFO:experiment:Saving cumulative regrets in output/s/results_3.json\n",
      "INFO:experiment:LOADING DATA\n",
      "INFO:experiment:Loading playlist data\n",
      "INFO:experiment:Loading user data\n",
      " \n",
      "\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3382: DtypeWarning: Columns (0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  if await self.run_code(code, result, async_=asy):\n",
      "INFO:experiment:SETTING UP SIMULATION ENVIRONMENT\n",
      "INFO:experiment:for 9749 users, 862 playlists, 12 recommendations per carousel \n",
      " \n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can't multiply sequence by non-int of type 'float'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[51], line 10\u001B[0m\n\u001B[1;32m      8\u001B[0m i \u001B[38;5;241m=\u001B[39m f\u001B[38;5;241m.\u001B[39msplit(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m)[\u001B[38;5;241m0\u001B[39m][\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]\n\u001B[1;32m      9\u001B[0m f \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdata/split/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mf\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m---> 10\u001B[0m \u001B[43mrun_experiment\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     11\u001B[0m \u001B[43m        \u001B[49m\u001B[43musers_path\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     12\u001B[0m \u001B[43m        \u001B[49m\u001B[43mplaylists_path\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mdata/playlist_features.csv\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     13\u001B[0m \u001B[43m        \u001B[49m\u001B[43moutput_path\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43mf\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43moutput/s/results_\u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43mi\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;124;43m.json\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     14\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpolicies\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mall_policies\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     15\u001B[0m \u001B[43m        \u001B[49m\u001B[43mn_recos\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m12\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     16\u001B[0m \u001B[43m        \u001B[49m\u001B[43ml_init\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m3\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     17\u001B[0m \u001B[43m        \u001B[49m\u001B[43mn_users_per_round\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m     18\u001B[0m \u001B[43m        \u001B[49m\u001B[43mn_rounds\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m100\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     19\u001B[0m \u001B[43m        \u001B[49m\u001B[43mprint_every\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m25\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     20\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/Uni/TU/DS Experiment Design/exercise 2/carousel_reproduction/experiment.py:98\u001B[0m, in \u001B[0;36mrun_experiment\u001B[0;34m(users_path, playlists_path, output_path, policies, n_recos, l_init, n_users_per_round, n_rounds, print_every, user_indices)\u001B[0m\n\u001B[1;32m     95\u001B[0m logger\u001B[38;5;241m.\u001B[39minfo(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSETTING UP SIMULATION ENVIRONMENT\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     96\u001B[0m logger\u001B[38;5;241m.\u001B[39minfo(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfor \u001B[39m\u001B[38;5;132;01m%d\u001B[39;00m\u001B[38;5;124m users, \u001B[39m\u001B[38;5;132;01m%d\u001B[39;00m\u001B[38;5;124m playlists, \u001B[39m\u001B[38;5;132;01m%d\u001B[39;00m\u001B[38;5;124m recommendations per carousel \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m (n_users, n_playlists, n_recos))\n\u001B[0;32m---> 98\u001B[0m cont_env \u001B[38;5;241m=\u001B[39m \u001B[43mContextualEnvironment\u001B[49m\u001B[43m(\u001B[49m\u001B[43muser_features\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mplaylist_features\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43muser_segment\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_recos\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    100\u001B[0m logger\u001B[38;5;241m.\u001B[39minfo(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSETTING UP POLICIES\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    101\u001B[0m logger\u001B[38;5;241m.\u001B[39minfo(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPolicies to evaluate: \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m (args\u001B[38;5;241m.\u001B[39mpolicies))\n",
      "File \u001B[0;32m~/Documents/Uni/TU/DS Experiment Design/exercise 2/carousel_reproduction/environment.py:15\u001B[0m, in \u001B[0;36mContextualEnvironment.__init__\u001B[0;34m(self, user_features, playlist_features, user_segment, n_recos)\u001B[0m\n\u001B[1;32m     13\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mth_segment_rewards \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mzeros(user_features\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m])\n\u001B[1;32m     14\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mth_rewards \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mzeros(user_features\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m])\n\u001B[0;32m---> 15\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcompute_optimal_theoretical_rewards\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     16\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcompute_segment_optimal_theoretical_rewards()\n",
      "File \u001B[0;32m~/Documents/Uni/TU/DS Experiment Design/exercise 2/carousel_reproduction/environment.py:48\u001B[0m, in \u001B[0;36mContextualEnvironment.compute_optimal_theoretical_rewards\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     46\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m u \u001B[38;5;241m<\u001B[39m n_users:\n\u001B[1;32m     47\u001B[0m     users_ids \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mrange\u001B[39m(u, \u001B[38;5;28mmin\u001B[39m(n_users, u \u001B[38;5;241m+\u001B[39m step))\n\u001B[0;32m---> 48\u001B[0m     opt_recos \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcompute_optimal_recos\u001B[49m\u001B[43m(\u001B[49m\u001B[43musers_ids\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mn_recos\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     49\u001B[0m     opt_rewards \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcompute_theoretical_rewards(users_ids, opt_recos)\n\u001B[1;32m     50\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mth_rewards[u:\u001B[38;5;28mmin\u001B[39m(n_users, u \u001B[38;5;241m+\u001B[39m step)] \u001B[38;5;241m=\u001B[39m opt_rewards\n",
      "File \u001B[0;32m~/Documents/Uni/TU/DS Experiment Design/exercise 2/carousel_reproduction/environment.py:33\u001B[0m, in \u001B[0;36mContextualEnvironment.compute_optimal_recos\u001B[0;34m(self, batch_user_ids, n)\u001B[0m\n\u001B[1;32m     31\u001B[0m batch_user_features \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mtake(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39muser_features, batch_user_ids, axis \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m)\n\u001B[1;32m     32\u001B[0m n_users \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(batch_user_ids)\n\u001B[0;32m---> 33\u001B[0m probas \u001B[38;5;241m=\u001B[39m \u001B[43mbatch_user_features\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdot\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mplaylist_features\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mT\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     34\u001B[0m optim \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39margsort(\u001B[38;5;241m-\u001B[39mprobas)[:, :n]\n\u001B[1;32m     35\u001B[0m \u001B[38;5;66;03m# return the list of indices in order\u001B[39;00m\n\u001B[1;32m     36\u001B[0m \u001B[38;5;66;03m# e.g. if the third playlist is best and the fifth is second best and n=2\u001B[39;00m\n\u001B[1;32m     37\u001B[0m \u001B[38;5;66;03m# [2, 4]\u001B[39;00m\n",
      "\u001B[0;31mTypeError\u001B[0m: can't multiply sequence by non-int of type 'float'"
     ]
    }
   ],
   "source": [
    "from experiment import run_experiment\n",
    "\n",
    "\n",
    "all_policies = \"random,etc-seg-explore,etc-seg-exploit,epsilon-greedy-explore,epsilon-greedy-exploit,kl-ucb-seg,ts-seg-naive,ts-seg-pessimistic,ts-lin-naive,ts-lin-pessimistic\"\n",
    "\n",
    "for f in os.listdir(\"data/split\"):\n",
    "        if \"DS_Store\" in f: continue\n",
    "        i = f.split(\".\")[0][-1]\n",
    "        f = f\"data/split/{f}\"\n",
    "        run_experiment(\n",
    "                users_path=f,\n",
    "                playlists_path=\"data/playlist_features.csv\",\n",
    "                output_path=f\"output/s/results_{i}.json\",\n",
    "                policies=all_policies,\n",
    "                n_recos=12,\n",
    "                l_init=3,\n",
    "                n_users_per_round=None,\n",
    "                n_rounds=100,\n",
    "                print_every=25,\n",
    "        )\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "data": {
      "text/plain": "['results_3.json']"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(\"output/s\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "import json"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "with open(\"output/s/results_3.json\", \"r\") as f:\n",
    "        res3 = json.load(f)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "data": {
      "text/plain": "array([['random', '639927.0835794248'],\n       ['etc-seg-explore', '607537.0835794248'],\n       ['etc-seg-exploit', '204077.0835794248'],\n       ['epsilon-greedy-explore', '145837.0835794249'],\n       ['epsilon-greedy-exploit', '180067.08357942486'],\n       ['kl-ucb-seg', '361742.08357942494'],\n       ['ts-seg-naive', '181456.08357942486'],\n       ['ts-seg-pessimistic', '110566.08357942494'],\n       ['ts-lin-naive', '183840.08357942486'],\n       ['ts-lin-pessimistic', '190586.08357942486']], dtype='<U22')"
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = [[key, value[-1]] for key, value in res3.items()]\n",
    "np.array(res)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
