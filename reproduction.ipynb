{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f912da7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /Users/nikolaus/opt/anaconda3/lib/python3.9/site-packages (1.21.5)\r\n",
      "Requirement already satisfied: pandas in /Users/nikolaus/opt/anaconda3/lib/python3.9/site-packages (1.4.4)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/nikolaus/opt/anaconda3/lib/python3.9/site-packages (from pandas) (2.8.2)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/nikolaus/opt/anaconda3/lib/python3.9/site-packages (from pandas) (2022.1)\r\n",
      "Requirement already satisfied: numpy>=1.18.5 in /Users/nikolaus/opt/anaconda3/lib/python3.9/site-packages (from pandas) (1.21.5)\r\n",
      "Requirement already satisfied: six>=1.5 in /Users/nikolaus/opt/anaconda3/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\r\n",
      "Requirement already satisfied: scipy in /Users/nikolaus/opt/anaconda3/lib/python3.9/site-packages (1.9.1)\r\n",
      "Requirement already satisfied: numpy<1.25.0,>=1.18.5 in /Users/nikolaus/opt/anaconda3/lib/python3.9/site-packages (from scipy) (1.21.5)\r\n"
     ]
    }
   ],
   "source": [
    "# installations\n",
    "!pip install numpy\n",
    "!pip install pandas\n",
    "!pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Running a test\n",
    "The following chunk runs a lightweight version of the experiment once, with only a handful of users.\n",
    "At each round, the model gets fitted to every user in the dataset and a regret score is calculated.\n",
    "At the end of all rounds (by default 100 rounds) the minimum cumulative regret indicates, which model performs best.\n",
    "According to the source paper, *ts-seg-pessimistic* performs best on the offline experiment. Hence, they tested this models performance in a cascade versus non-cascade offline experiment, in which case the *ts-seg-pessimistic cascade* model performed best. This model also caused the highest display-to-stream gain.\n",
    "All featured tests' results showed statistical significance at the 1% level. However, the paper does not state how those statistical tests were conducted.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:__main__:LOADING DATA\r\n",
      "INFO:__main__:Loading playlist data\r\n",
      "INFO:__main__:Loading user data\r\n",
      " \r\n",
      "\r\n",
      "9\r\n",
      "9\r\n",
      "1.0\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/Users/nikolaus/Documents/Uni/TU/DS Experiment Design/exercise 2/carousel_reproduction/main.py\", line 79, in <module>\r\n",
      "    raise hell\r\n",
      "NameError: name 'hell' is not defined\r\n",
      "Figure(640x480)\r\n"
     ]
    }
   ],
   "source": [
    "# small dataset, all policies\n",
    "!python main.py --users_path data/user_features_small.csv --policies random,etc-seg-explore,etc-seg-exploit,epsilon-greedy-explore,epsilon-greedy-exploit,kl-ucb-seg,ts-seg-naive,ts-seg-pessimistic,ts-lin-naive,ts-lin-pessimistic --n_users_per_round 9 --output_path general_experiment_results.json\n",
    "!python plot_results.py --data_path general_experiment_results.json\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:__main__:LOADING DATA\r\n",
      "INFO:__main__:Loading playlist data\r\n",
      "INFO:__main__:Loading user data\r\n",
      " \r\n",
      "\r\n",
      "974960\r\n",
      "20000\r\n",
      "0.020513662098957906\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/Users/nikolaus/Documents/Uni/TU/DS Experiment Design/exercise 2/carousel_reproduction/main.py\", line 79, in <module>\r\n",
      "    raise hell\r\n",
      "NameError: name 'hell' is not defined\r\n",
      "Figure(640x480)\r\n"
     ]
    }
   ],
   "source": [
    "# full dataset, two policies\n",
    "!python main.py --policies random,ts-seg-pessimistic --print_every 5 --output_path general_experiment_results.json\n",
    "!python plot_results.py --data_path general_experiment_results.json"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# My suggestion for reproducing tests\n",
    "We can reproduce the full offline experiment. We just need to find a way to compare results.\n",
    "https://machinelearningmastery.com/statistical-significance-tests-for-comparing-machine-learning-algorithms/\n",
    "According to this paper, it is common to do a 10-fold cross validation on the dataset at hand and grab the mean/median success metric of each model as a statistic for that model. We would then have the following hypotheses:\n",
    " * h0: there is no difference in model performances, i.e. ts-seg-pessimistic (cascade) performs just as well as the other models, i.e. the lower cumulative regret of the tests are due to chance\n",
    "  * h1: there is a difference in model performances, i.e. ts-seg-pessimistic (cascade) outperforms the other models\n",
    "\n",
    "### Does the original code cross-validate?\n",
    "No, but something different. The argument *n_users_per_round* (default 20.000, 1% of full dataset) states, how many users actually get recommended anything in any round. That means that the actual dataset never changes for every time you run the experiment, but the sample on which you fit and evaluate the model changes on every round.\n",
    "According to Brownlee (2018, https://machinelearningmastery.com/statistical-significance-tests-for-comparing-machine-learning-algorithms/), this testing behaviour violates a key assumption of the Student's t-test, which is independency of observations in each sample per round.\n",
    "My suggestion for fixing this. Run the full experiment k (10) times and give the program either 10% of the data to work on, while either continuing to let it use a sample of 20.000 users or even telling it not to resample anything, but rather work on the whole data. Instead of rewriting the source code to include cross-validation, I will split the users dataset itself into k samples and run the whole main.py file k times, with different arguments each time, i.e. changing the results-output-filename.\n",
    "The only rewriting I will do, is putting the main workflow of the main.py file into a separate main() function with arguments passed in python rather than from the command line, so I can execute it using this notebook.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "run_experiment() got an unexpected keyword argument 'user_indices'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/wn/h7d3tkjj12g2j3lhccrbhnlc0000gn/T/ipykernel_7463/3996365567.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mexperiment\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mrun_experiment\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 4\u001B[0;31m run_experiment(\n\u001B[0m\u001B[1;32m      5\u001B[0m         \u001B[0musers_path\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m\"data/user_features.csv\"\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      6\u001B[0m         \u001B[0mplaylists_path\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m\"data/playlist_features.csv\"\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mTypeError\u001B[0m: run_experiment() got an unexpected keyword argument 'user_indices'"
     ]
    }
   ],
   "source": [
    "# test run of the new experiment.py\n",
    "\n",
    "from experiment import run_experiment\n",
    "run_experiment(\n",
    "        users_path=\"data/user_features.csv\",\n",
    "        playlists_path=\"data/playlist_features.csv\",\n",
    "        output_path=\"results.json\",\n",
    "        policies=\"random,ts-seg-naive\",\n",
    "        n_recos=12,\n",
    "        l_init=3,\n",
    "        n_users_per_round=20000,\n",
    "        n_rounds=100,\n",
    "        print_every=10,\n",
    "        user_indices=[3, 6, 7, 9, 12, 36, 47]\n",
    "\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting 97497 rows from user_features_s.csv into 10 files with 9749 rows each ...\n",
      "\t saving file number 0: [85946  3872 31780 ... 47937 55567 82517]\n",
      "\t saving file number 1: [22586 31592 96232 ... 73702 64310 54891]\n",
      "\t saving file number 2: [76709 75098  2673 ...  5544 56415 92977]\n",
      "\t saving file number 3: [63423 41334 63777 ... 60094 15604 37713]\n",
      "\t saving file number 4: [19728 31058 70798 ... 16191 62876 61679]\n",
      "\t saving file number 5: [88045 25461  6879 ... 32632 20313 31835]\n",
      "\t saving file number 6: [94082 32249 73644 ... 48007 74561  1241]\n",
      "\t saving file number 7: [69563 19952 90072 ... 81243 24419 55885]\n",
      "\t saving file number 8: [10380  9242 92649 ... 37100 44500 91414]\n",
      "\t saving file number 9: [50418 58201 96554 ... 38744 74385 92454]\n",
      "All done. 7 users remain unsaved: [ 4459  8820 14441 42417 69647 69973 93180]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def split_dataset(data_filename, k):\n",
    "        # grabs a datafile from the folder \"data/\"\n",
    "        # randomly splits the dataset into k smaller sets of equal size\n",
    "        # saves them in the folder \"data/split/\"\n",
    "\n",
    "        with open(f\"data/{data_filename}\", \"r\") as f:\n",
    "                full = np.array(f.readlines())\n",
    "\n",
    "        data_filename, suffix = data_filename.split(\".\")\n",
    "\n",
    "        # header row should be separate\n",
    "        header_row, full = full[0], full[0:]\n",
    "\n",
    "        N = len(full) # number of all rows\n",
    "        indices = np.array(list((range(N)))) # numbers from 0 to N\n",
    "        n = N // k # number of rows per k\n",
    "\n",
    "        print(f\"Splitting {N} rows from {data_filename}.{suffix} into {k} files with {n} rows each ...\")\n",
    "\n",
    "        for i in range(k):\n",
    "                # get random row numbers from 0 to the length of indices (starts at N)\n",
    "                random_indices = np.random.choice(len(indices), n, replace=False)\n",
    "                # grab random row numbers of the remaining ones\n",
    "                sample_indices = indices[random_indices]\n",
    "                # remove the selected row numbers from the indices list\n",
    "                indices = np.delete(indices, random_indices)\n",
    "                # create a sample\n",
    "                sample = full[sample_indices]\n",
    "                # add the header row\n",
    "                sample = np.append(header_row, sample)\n",
    "                # save the sample\n",
    "                print(f\"\\t saving file number {i}: {sample_indices}\")\n",
    "                f = f\"data/split/{data_filename}_{i}.{suffix}\"\n",
    "                with open(f, \"w\") as f:\n",
    "                        f.writelines(list(sample))\n",
    "\n",
    "\n",
    "        print(f\"All done. {len(indices)} users remain unsaved: {indices}\")\n",
    "        print()\n",
    "        del full\n",
    "        del indices\n",
    "        del sample\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Preparing k datasets\n",
    "data_filename = \"user_features.csv\"\n",
    "data_filename = \"user_features_s.csv\"\n",
    "\n",
    "k = 10\n",
    "\n",
    "split_dataset(data_filename, k)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Data for testing\n",
    "* data/split/: small data\n",
    "* data/splitL: big data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:experiment:LOADING DATA\n",
      "INFO:experiment:Loading playlist data\n",
      "INFO:experiment:Loading user data\n",
      " \n",
      "\n",
      "INFO:experiment:SETTING UP SIMULATION ENVIRONMENT\n",
      "INFO:experiment:for 9749 users, 862 playlists, 12 recommendations per carousel \n",
      " \n",
      "\n",
      "INFO:experiment:SETTING UP POLICIES\n",
      "INFO:experiment:Policies to evaluate: random,etc-seg-explore,etc-seg-exploit,epsilon-greedy-explore,epsilon-greedy-exploit,kl-ucb-seg,ts-seg-naive,ts-seg-pessimistic,ts-lin-naive,ts-lin-pessimistic \n",
      " \n",
      "\n",
      "INFO:experiment:STARTING SIMULATIONS\n",
      "INFO:experiment:for 100 rounds, with 9749 users per round (randomly drawn with replacement)\n",
      " \n",
      "\n",
      "INFO:experiment:Round: 1/100. Elapsed time: 230.721847 sec.\n",
      "INFO:experiment:Cumulative regrets: \n",
      "\trandom : 6394.4675012742355\n",
      "\tetc-seg-explore : 6397.4675012742355\n",
      "\tetc-seg-exploit : 6418.4675012742355\n",
      "\tepsilon-greedy-explore : 6456.4675012742355\n",
      "\tepsilon-greedy-exploit : 6379.4675012742355\n",
      "\tkl-ucb-seg : 6384.4675012742355\n",
      "\tts-seg-naive : 6366.4675012742355\n",
      "\tts-seg-pessimistic : 6334.4675012742355\n",
      "\tts-lin-naive : 6374.4675012742355\n",
      "\tts-lin-pessimistic : 6435.4675012742355 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from experiment import run_experiment\n",
    "\n",
    "\n",
    "all_policies = \"random,etc-seg-explore,etc-seg-exploit,epsilon-greedy-explore,epsilon-greedy-exploit,kl-ucb-seg,ts-seg-naive,ts-seg-pessimistic,ts-lin-naive,ts-lin-pessimistic\"\n",
    "\n",
    "for f in os.listdir(\"data/split\"):\n",
    "        if \"DS_Store\" in f: continue\n",
    "        i = f.split(\".\")[0][-1]\n",
    "        f = f\"data/split/{f}\"\n",
    "        run_experiment(\n",
    "                users_path=f,\n",
    "                playlists_path=\"data/playlist_features.csv\",\n",
    "                output_path=f\"output/s/results_{i}.json\",\n",
    "                policies=all_policies,\n",
    "                n_recos=12,\n",
    "                l_init=3,\n",
    "                n_users_per_round=None,\n",
    "                n_rounds=100,\n",
    "                print_every=25,\n",
    "        )\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "data": {
      "text/plain": "['results_3.json']"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(\"output/s\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "import json"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "with open(\"output/s/results_3.json\", \"r\") as f:\n",
    "        res3 = json.load(f)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "data": {
      "text/plain": "array([['random', '639927.0835794248'],\n       ['etc-seg-explore', '607537.0835794248'],\n       ['etc-seg-exploit', '204077.0835794248'],\n       ['epsilon-greedy-explore', '145837.0835794249'],\n       ['epsilon-greedy-exploit', '180067.08357942486'],\n       ['kl-ucb-seg', '361742.08357942494'],\n       ['ts-seg-naive', '181456.08357942486'],\n       ['ts-seg-pessimistic', '110566.08357942494'],\n       ['ts-lin-naive', '183840.08357942486'],\n       ['ts-lin-pessimistic', '190586.08357942486']], dtype='<U22')"
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = [[key, value[-1]] for key, value in res3.items()]\n",
    "np.array(res)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "data": {
      "text/plain": "array(['random', '639927.0835794248', 'random', '639927.0835794248',\n       'etc-seg-explore', '607537.0835794248', 'etc-seg-exploit',\n       '204077.0835794248', 'epsilon-greedy-explore', '145837.0835794249',\n       'epsilon-greedy-exploit', '180067.08357942486', 'kl-ucb-seg',\n       '361742.08357942494', 'ts-seg-naive', '181456.08357942486',\n       'ts-seg-pessimistic', '110566.08357942494', 'ts-lin-naive',\n       '183840.08357942486', 'ts-lin-pessimistic', '190586.08357942486'],\n      dtype='<U22')"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
